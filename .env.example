# Biomni Environment Configuration
# Copy this file to .env and fill in your actual API keys

# Required: Anthropic API Key for Claude models
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Optional: OpenAI API Key (if using OpenAI models)
OPENAI_API_KEY=your_openai_api_key_here

# Optional: AWS Bedrock Configuration (if using AWS Bedrock models)
AWS_BEARER_TOKEN_BEDROCK=your_bedrock_api_key_here
AWS_REGION=us-east-1

# Optional: Custom model serving configuration
# CUSTOM_MODEL_BASE_URL=http://localhost:8000/v1
# CUSTOM_MODEL_API_KEY=your_custom_api_key_here

# Optional: Biomni data path (defaults to ./data)
# BIOMNI_DATA_PATH=/path/to/your/data

# Optional: Timeout settings
# BIOMNI_TIMEOUT_SECONDS=600

# Optional: Maximum output tokens for LLM generation
# Claude 3.5 Sonnet: max 8192, Claude 4.x may support higher limits
# BIOMNI_MAX_TOKENS=8192

# Optional: LLM API timeout in seconds (for Bedrock/API calls)
# Increase for very long token generation (e.g., 600 for large responses)
# BIOMNI_LLM_TIMEOUT=300

# Optional: Tool blacklist - comma-separated list of tool names to disable
# Useful for restricting access to certain tools (e.g., public web search)
# BIOMNI_TOOL_BLACKLIST=advanced_web_search_claude,search_google,fetch_supplementary_info_from_doi

# Optional: LangSmith Tracing (for debugging and monitoring LLM calls)
# LANGSMITH_TRACING=true
# LANGSMITH_PROJECT=biomni
# LANGCHAIN_ENDPOINT=https://eu.api.smith.langchain.com
# LANGSMITH_API_KEY=<your-token>